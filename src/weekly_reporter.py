"""Weekly report generator"""
import logging
from datetime import date
from typing import List, Dict
from collections import Counter
from openai import OpenAI
from src.database import Database


logger = logging.getLogger(__name__)


def _normalize_base_url(base_url: str) -> str:
    """Normalize OpenAI-compatible base URL to local proxy path."""
    normalized = base_url.rstrip("/")
    if normalized.endswith("/v1"):
        return normalized
    return f"{normalized}/v1"


class WeeklyReporter:
    """Generate weekly AI trends report"""

    def __init__(
        self,
        database: Database,
        ai_base_url: str,
        ai_api_key: str,
        ai_model: str
    ):
        """
        Initialize weekly reporter

        Args:
            database: Database instance
            ai_base_url: LLM API base URL
            ai_api_key: LLM API key
            ai_model: LLM model name
        """
        self.db = database
        normalized_base_url = _normalize_base_url(ai_base_url)
        self.llm = OpenAI(base_url=normalized_base_url, api_key=ai_api_key)
        self.model = ai_model

    def generate_report(
        self,
        week_start: date,
        week_end: date,
        max_projects: int = 25
    ) -> str:
        """
        Generate weekly report

        Args:
            week_start: Start date (Monday)
            week_end: End date (Friday)
            max_projects: Maximum projects to include

        Returns:
            Formatted markdown report
        """
        # Fetch weekly trends
        trends = self.db.get_weekly_trends(week_start, week_end)

        if not trends:
            return self._format_empty_report(week_start, week_end)

        # Deduplicate (keep highest stars for each project)
        unique_projects = self._deduplicate_projects(trends)

        # Limit to max_projects
        top_projects = unique_projects[:max_projects]

        # Generate LLM analysis
        tech_trends = self._analyze_trends(top_projects)

        # Format report
        report = self._format_report(
            week_start,
            week_end,
            top_projects,
            tech_trends
        )

        return report

    def _deduplicate_projects(self, trends: List[Dict]) -> List[Dict]:
        """Deduplicate projects, keeping highest stars"""
        projects_map = {}

        for trend in trends:
            repo_name = trend['repo_name']
            if repo_name not in projects_map or trend['stars'] > projects_map[repo_name]['stars']:
                projects_map[repo_name] = trend

        # Sort by stars_growth and stars
        unique = list(projects_map.values())
        unique.sort(key=lambda x: (x['stars_growth'], x['stars']), reverse=True)

        return unique

    def _analyze_trends(self, projects: List[Dict]) -> str:
        """Use LLM to analyze technology trends"""

        # Prepare project summary
        summary = []
        for p in projects[:10]:  # Analyze top 10
            summary.append(f"- {p['repo_name']}: {p['description']} ({p['language']})")

        prompt = f"""åˆ†æä»¥ä¸‹æœ¬å‘¨GitHub AIè¶‹åŠ¿é¡¹ç›®ï¼Œæ€»ç»“æŠ€æœ¯è¶‹åŠ¿å’Œçƒ­ç‚¹æ–¹å‘ï¼ˆ2-3æ¡è¦ç‚¹ï¼‰ï¼š

{chr(10).join(summary)}

è¯·è¿”å›ç®€æ´çš„è¶‹åŠ¿åˆ†æï¼ˆæ¯æ¡1å¥è¯ï¼‰ã€‚"""

        try:
            response = self.llm.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯AIæŠ€æœ¯è¶‹åŠ¿åˆ†æä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=300
            )

            return response.choices[0].message.content

        except Exception as e:
            logger.warning(f"LLM trend analysis failed: {e}")
            return "æœ¬å‘¨AIé¡¹ç›®æŒç»­æ´»è·ƒï¼Œæ¶µç›–å¤šä¸ªæŠ€æœ¯æ–¹å‘ã€‚"

    def _categorize_projects(self, projects: List[Dict]) -> Dict[str, int]:
        """Categorize projects by technology area"""
        categories = {
            'LLM/NLP': 0,
            'è®¡ç®—æœºè§†è§‰': 0,
            'AIå·¥å…·/æ¡†æ¶': 0,
            'å¤šæ¨¡æ€åº”ç”¨': 0,
            'å…¶ä»–': 0
        }

        for p in projects:
            reason = p.get('ai_relevance_reason', '').lower()
            desc = p.get('description', '').lower()
            text = reason + ' ' + desc

            if any(kw in text for kw in ['llm', 'nlp', 'language', 'gpt', 'chatbot', 'embedding']):
                categories['LLM/NLP'] += 1
            elif any(kw in text for kw in ['vision', 'image', 'video', 'opencv', 'detection']):
                categories['è®¡ç®—æœºè§†è§‰'] += 1
            elif any(kw in text for kw in ['framework', 'tool', 'library', 'platform']):
                categories['AIå·¥å…·/æ¡†æ¶'] += 1
            elif any(kw in text for kw in ['multimodal', 'multi-modal', 'audio', 'speech']):
                categories['å¤šæ¨¡æ€åº”ç”¨'] += 1
            else:
                categories['å…¶ä»–'] += 1

        return categories

    def _format_report(
        self,
        week_start: date,
        week_end: date,
        projects: List[Dict],
        tech_trends: str
    ) -> str:
        """Format weekly report"""

        total_stars = sum(p['stars_growth'] for p in projects)
        categories = self._categorize_projects(projects)

        lines = [
            "ğŸ“Š **æœ¬å‘¨AIè¶‹åŠ¿å‘¨æŠ¥**",
            f"\nğŸ“… {week_start.strftime('%Y-%m-%d')} ~ {week_end.strftime('%Y-%m-%d')}",
            "\n## ğŸ“ˆ æœ¬å‘¨æ¦‚è§ˆ",
            f"- å‘ç° **{len(projects)}** ä¸ªAIç›¸å…³é¡¹ç›®",
            f"- æ€»è®¡æ–°å¢ **{total_stars:,}** stars",
            "\n## ğŸ† çƒ­é—¨é¡¹ç›® Top 10\n"
        ]

        # Top 10 projects
        for idx, p in enumerate(projects[:10], 1):
            lines.extend([
                f"{idx}. **{p['repo_name']}** â­ {p['stars']:,} (+{p['stars_growth']})",
                f"   ğŸ“ {p['description'][:80]}..." if len(p['description']) > 80 else f"   ğŸ“ {p['description']}",
                f"   ğŸ”— [æŸ¥çœ‹é¡¹ç›®]({p['url']})\n"
            ])

        # Tech trends
        lines.extend([
            "\n## ğŸ”¥ æŠ€æœ¯è¶‹åŠ¿åˆ†æ",
            tech_trends,
            "\n## ğŸ“Š åˆ†ç±»ç»Ÿè®¡"
        ])

        for category, count in categories.items():
            if count > 0:
                emoji = self._get_category_emoji(category)
                lines.append(f"- {emoji} {category}: {count}ä¸ª")

        lines.append("\n---\nâ° ç”±GitHub-Trend-Botè‡ªåŠ¨æ¨é€")

        return "\n".join(lines)

    def _format_empty_report(self, week_start: date, week_end: date) -> str:
        """Format empty report when no data"""
        return f"""ğŸ“Š **æœ¬å‘¨AIè¶‹åŠ¿å‘¨æŠ¥**

ğŸ“… {week_start.strftime('%Y-%m-%d')} ~ {week_end.strftime('%Y-%m-%d')}

âš ï¸ æœ¬å‘¨æš‚æ— AIè¶‹åŠ¿æ•°æ®

---
â° ç”±GitHub-Trend-Botè‡ªåŠ¨æ¨é€"""

    def _get_category_emoji(self, category: str) -> str:
        """Get emoji for category"""
        emoji_map = {
            'LLM/NLP': 'ğŸ¤–',
            'è®¡ç®—æœºè§†è§‰': 'ğŸ‘',
            'AIå·¥å…·/æ¡†æ¶': 'ğŸ› ',
            'å¤šæ¨¡æ€åº”ç”¨': 'ğŸ¨',
            'å…¶ä»–': 'ğŸ“¦'
        }
        return emoji_map.get(category, 'ğŸ“¦')
