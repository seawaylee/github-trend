"""Weekly report generator"""
import logging
from datetime import date
from typing import List, Dict
from openai import OpenAI
from src.database import Database


logger = logging.getLogger(__name__)


def _normalize_base_url(base_url: str) -> str:
    """Normalize OpenAI-compatible base URL to local proxy path."""
    normalized = base_url.rstrip("/")
    if normalized.endswith("/v1"):
        return normalized
    return f"{normalized}/v1"


class WeeklyReporter:
    """Generate weekly AI trends report"""

    def __init__(
        self,
        database: Database,
        ai_base_url: str,
        ai_api_key: str,
        ai_model: str
    ):
        """
        Initialize weekly reporter

        Args:
            database: Database instance
            ai_base_url: LLM API base URL
            ai_api_key: LLM API key
            ai_model: LLM model name
        """
        self.db = database
        normalized_base_url = _normalize_base_url(ai_base_url)
        self.llm = OpenAI(base_url=normalized_base_url, api_key=ai_api_key)
        self.model = ai_model

    def generate_report(
        self,
        week_start: date,
        week_end: date,
        max_projects: int = 25
    ) -> str:
        """
        Generate weekly report

        Args:
            week_start: Start date (Monday)
            week_end: End date (Friday)
            max_projects: Maximum projects to include

        Returns:
            Formatted markdown report
        """
        report_package = self.generate_report_package(week_start, week_end, max_projects)
        return report_package["report"]

    def generate_report_package(
        self,
        week_start: date,
        week_end: date,
        max_projects: int = 25
    ) -> Dict[str, str]:
        """
        Generate weekly report + standalone summary for split push.

        Returns:
            Dict with keys:
            - report: Top projects + trend analysis
            - summary: AI summary and business value analysis content
        """
        # Fetch weekly trends
        trends = self.db.get_weekly_trends(week_start, week_end)

        if not trends:
            return {
                "report": self._format_empty_report(week_start, week_end),
                "summary": self._format_empty_summary()
            }

        # Deduplicate (keep highest stars for each project)
        unique_projects = self._deduplicate_projects(trends)

        # Limit to max_projects
        top_projects = unique_projects[:max_projects]

        # Generate LLM analysis
        tech_trends = self._analyze_trends(top_projects)
        weekly_summary = self._analyze_weekly_summary(top_projects, tech_trends)

        # Format report
        report = self._format_report(
            week_start,
            week_end,
            top_projects,
            tech_trends
        )

        return {
            "report": report,
            "summary": weekly_summary
        }

    def _deduplicate_projects(self, trends: List[Dict]) -> List[Dict]:
        """Deduplicate projects, keeping highest stars"""
        projects_map = {}

        for trend in trends:
            repo_name = trend['repo_name']
            if repo_name not in projects_map or trend['stars'] > projects_map[repo_name]['stars']:
                projects_map[repo_name] = trend

        # Sort by stars_growth and stars
        unique = list(projects_map.values())
        unique.sort(key=lambda x: (x['stars_growth'], x['stars']), reverse=True)

        return unique

    def _analyze_trends(self, projects: List[Dict]) -> str:
        """Use LLM to analyze technology trends"""

        # Prepare project summary
        summary = []
        for p in projects[:10]:  # Analyze top 10
            summary.append(
                f"- {p['repo_name']}: {p.get('description') or ''} ({p.get('language') or 'Unknown'})"
            )

        prompt = f"""åˆ†æä»¥ä¸‹æœ¬å‘¨GitHub AIè¶‹åŠ¿é¡¹ç›®ï¼Œæ€»ç»“æŠ€æœ¯è¶‹åŠ¿å’Œçƒ­ç‚¹æ–¹å‘ï¼ˆ2-3æ¡è¦ç‚¹ï¼‰ï¼š

{chr(10).join(summary)}

è¯·è¿”å›ç®€æ´çš„è¶‹åŠ¿åˆ†æï¼ˆæ¯æ¡1å¥è¯ï¼‰ã€‚"""

        try:
            response = self.llm.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯AIæŠ€æœ¯è¶‹åŠ¿åˆ†æä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=300
            )

            return response.choices[0].message.content

        except Exception as e:
            logger.warning(f"LLM trend analysis failed: {e}")
            return "æœ¬å‘¨AIé¡¹ç›®æŒç»­æ´»è·ƒï¼Œæ¶µç›–å¤šä¸ªæŠ€æœ¯æ–¹å‘ã€‚"

    def _analyze_weekly_summary(self, projects: List[Dict], tech_trends: str) -> str:
        """Generate weekly AI summary and business value analysis."""
        if not projects:
            return self._format_empty_summary()

        project_lines = []
        for idx, project in enumerate(projects[:8], 1):
            project_lines.append(
                f"{idx}. {project['repo_name']}: {project.get('description') or ''} "
                f"(Language: {project.get('language') or 'Unknown'})"
            )

        prompt = f"""åˆ†æä»¥ä¸‹æœ¬å‘¨GitHubçƒ­é—¨AIé¡¹ç›®åˆ—è¡¨ï¼š

{chr(10).join(project_lines)}

è¡¥å……æŠ€æœ¯è¶‹åŠ¿å‚è€ƒï¼š
{tech_trends}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. ç»™å‡ºâ€œæœ¬å‘¨è¶‹åŠ¿æ€»ç»“â€ï¼ˆä¸€æ®µè¯ï¼Œèšç„¦æ ¸å¿ƒæŠ€æœ¯æ–¹å‘å’Œå˜åŒ–ï¼‰ã€‚
2. è¯„ä¼°è¿™äº›é¡¹ç›®å¯¹æœç‹ä¸šåŠ¡çš„ä»·å€¼ï¼Œé‡ç‚¹è¦†ç›–æœç´¢å¼•æ“ã€æ¨èç³»ç»Ÿã€AIåŸºç¡€è®¾æ–½ï¼ˆè®­ç»ƒ/æ¨ç†/éƒ¨ç½²ï¼‰ã€‚
   - ä»…åœ¨ç¡®å®ç›¸å…³æ—¶ç»™å‡ºé¡¹ç›®ä¸æ”¶ç›Šè¯´æ˜ï¼Œä¸è¦ç¼–é€ ã€‚

è¾“å‡ºè¦æ±‚ï¼š
- ä½¿ç”¨ Markdownã€‚
- å¿…é¡»åŒ…å«æ ‡é¢˜â€œ## æœ¬å‘¨è¶‹åŠ¿æ€»ç»“â€ã€‚
- å¿…é¡»åŒ…å«æ ‡é¢˜â€œğŸš€ **æœç‹ä¸šåŠ¡ä»·å€¼åˆ†æ**â€ã€‚
"""

        try:
            response = self.llm.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯èµ„æ·±AIæŠ€æœ¯æˆ˜ç•¥åˆ†æå¸ˆï¼Œæ“…é•¿æŠ€æœ¯è¶‹åŠ¿å’Œä¸šåŠ¡ä»·å€¼è¯„ä¼°ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,
                max_tokens=700
            )
            summary_text = response.choices[0].message.content.strip()
            return self._ensure_summary_sections(summary_text, projects)
        except Exception as e:
            logger.warning(f"LLM weekly summary failed: {e}")
            return self._build_fallback_summary(projects)

    def _ensure_summary_sections(self, summary_text: str, projects: List[Dict]) -> str:
        """Ensure summary contains required markdown sections."""
        content = (summary_text or "").strip()
        if not content:
            return self._build_fallback_summary(projects)

        if "æœ¬å‘¨è¶‹åŠ¿æ€»ç»“" not in content:
            content = f"## æœ¬å‘¨è¶‹åŠ¿æ€»ç»“\n\n{content}"

        if "æœç‹ä¸šåŠ¡ä»·å€¼åˆ†æ" not in content:
            content = (
                f"{content}\n\n"
                "ğŸš€ **æœç‹ä¸šåŠ¡ä»·å€¼åˆ†æ**\n\n"
                "- æš‚æœªè¯†åˆ«åˆ°ç›´æ¥å¯è½åœ°çš„ä¸šåŠ¡ä»·å€¼ï¼Œå»ºè®®æŒç»­è§‚å¯Ÿã€‚"
            )

        return content

    def _build_fallback_summary(self, projects: List[Dict]) -> str:
        """Build stable weekly summary when LLM output is unavailable."""
        top_names = "ã€".join([p["repo_name"] for p in projects[:3]]) or "æœ¬å‘¨ä¸Šæ¦œé¡¹ç›®"
        return (
            "## æœ¬å‘¨è¶‹åŠ¿æ€»ç»“\n\n"
            f"æœ¬å‘¨çƒ­ç‚¹ä¸»è¦é›†ä¸­åœ¨ Agentã€LLM åº”ç”¨ä¸å·¥ç¨‹å·¥å…·é“¾ï¼Œä»£è¡¨é¡¹ç›®åŒ…æ‹¬ï¼š{top_names}ã€‚\n\n"
            "ğŸš€ **æœç‹ä¸šåŠ¡ä»·å€¼åˆ†æ**\n\n"
            "- æœç´¢å¼•æ“ï¼šä¼˜å…ˆéªŒè¯æ£€ç´¢å¢å¼ºã€ç»“æœæ‘˜è¦ä¸ç»“æ„åŒ–ä¿¡æ¯æŠ½å–ã€‚\n"
            "- æ¨èç³»ç»Ÿï¼šå¯ç”¨äºå†…å®¹æ ‡ç­¾è¡¥å…¨ã€å†·å¯åŠ¨ç‰¹å¾ç”Ÿæˆä¸é‡æ’ä¼˜åŒ–ã€‚\n"
            "- AIåŸºç¡€è®¾æ–½ï¼šå»ºè®®æ¨è¿›ç»Ÿä¸€æ¨¡å‹ç½‘å…³ã€æ¨ç†æˆæœ¬æ²»ç†ä¸å¤šæ¨¡å‹å®¹ç¾ã€‚"
        )

    def _categorize_projects(self, projects: List[Dict]) -> Dict[str, int]:
        """Categorize projects by technology area"""
        categories = {
            'LLM/NLP': 0,
            'è®¡ç®—æœºè§†è§‰': 0,
            'AIå·¥å…·/æ¡†æ¶': 0,
            'å¤šæ¨¡æ€åº”ç”¨': 0,
            'å…¶ä»–': 0
        }

        for p in projects:
            reason = p.get('ai_relevance_reason', '').lower()
            desc = p.get('description', '').lower()
            text = reason + ' ' + desc

            if any(kw in text for kw in ['llm', 'nlp', 'language', 'gpt', 'chatbot', 'embedding']):
                categories['LLM/NLP'] += 1
            elif any(kw in text for kw in ['vision', 'image', 'video', 'opencv', 'detection']):
                categories['è®¡ç®—æœºè§†è§‰'] += 1
            elif any(kw in text for kw in ['framework', 'tool', 'library', 'platform']):
                categories['AIå·¥å…·/æ¡†æ¶'] += 1
            elif any(kw in text for kw in ['multimodal', 'multi-modal', 'audio', 'speech']):
                categories['å¤šæ¨¡æ€åº”ç”¨'] += 1
            else:
                categories['å…¶ä»–'] += 1

        return categories

    def _format_report(
        self,
        week_start: date,
        week_end: date,
        projects: List[Dict],
        tech_trends: str
    ) -> str:
        """Format weekly report"""

        total_stars = sum(p['stars_growth'] for p in projects)
        categories = self._categorize_projects(projects)

        lines = [
            "ğŸ“Š **æœ¬å‘¨AIè¶‹åŠ¿å‘¨æŠ¥**",
            f"\nğŸ“… {week_start.strftime('%Y-%m-%d')} ~ {week_end.strftime('%Y-%m-%d')}",
            "\n## ğŸ“ˆ æœ¬å‘¨æ¦‚è§ˆ",
            f"- å‘ç° **{len(projects)}** ä¸ªAIç›¸å…³é¡¹ç›®",
            f"- æ€»è®¡æ–°å¢ **{total_stars:,}** stars",
            "\n## ğŸ† çƒ­é—¨é¡¹ç›® Top 10\n"
        ]

        # Top 10 projects
        for idx, p in enumerate(projects[:10], 1):
            description = p.get('description') or ''
            raw_highlight = p.get('ai_relevance_reason') or ""
            ai_highlight = self._normalize_ai_highlight(raw_highlight, description)
            lines.extend([
                f"{idx}. **{p['repo_name']}** â­ {p['stars']:,} (+{p['stars_growth']})",
                f"   ğŸ“ {self._truncate_text(description, 80)}",
                f"   ğŸ’¡ AIäº®ç‚¹ï¼š{self._truncate_text(ai_highlight, 120)}",
                f"   ğŸ”— [æŸ¥çœ‹é¡¹ç›®]({p['url']})\n"
            ])

        # Tech trends
        lines.extend([
            "\n## ğŸ”¥ æŠ€æœ¯è¶‹åŠ¿åˆ†æ",
            tech_trends,
            "\n## ğŸ“Š åˆ†ç±»ç»Ÿè®¡"
        ])

        for category, count in categories.items():
            if count > 0:
                emoji = self._get_category_emoji(category)
                lines.append(f"- {emoji} {category}: {count}ä¸ª")

        lines.append("\n---\nâ° ç”±GitHub-Trend-Botè‡ªåŠ¨æ¨é€")

        return "\n".join(lines)

    def _format_empty_report(self, week_start: date, week_end: date) -> str:
        """Format empty report when no data"""
        return f"""ğŸ“Š **æœ¬å‘¨AIè¶‹åŠ¿å‘¨æŠ¥**

ğŸ“… {week_start.strftime('%Y-%m-%d')} ~ {week_end.strftime('%Y-%m-%d')}

âš ï¸ æœ¬å‘¨æš‚æ— AIè¶‹åŠ¿æ•°æ®

---
â° ç”±GitHub-Trend-Botè‡ªåŠ¨æ¨é€"""

    @staticmethod
    def _format_empty_summary() -> str:
        """Fallback summary when no weekly data."""
        return (
            "## æœ¬å‘¨è¶‹åŠ¿æ€»ç»“\n\n"
            "æœ¬å‘¨æš‚æ— å¯åˆ†æçš„AIè¶‹åŠ¿é¡¹ç›®ã€‚\n\n"
            "ğŸš€ **æœç‹ä¸šåŠ¡ä»·å€¼åˆ†æ**\n\n"
            "- æš‚æ— å¯è¯„ä¼°çš„é¡¹ç›®ã€‚"
        )

    @staticmethod
    def _truncate_text(text: str, max_length: int) -> str:
        """Truncate text with ellipsis when necessary."""
        if len(text) <= max_length:
            return text
        return text[:max_length] + "..."

    @staticmethod
    def _normalize_ai_highlight(reason: str, description: str = "") -> str:
        """Rewrite fallback/technical reasons into readable Chinese highlight."""
        normalized = (reason or "").strip()
        lower_reason = normalized.lower()
        fallback_markers = (
            "keyword-based detection",
            "keyword based detection",
            "llm unavailable"
        )
        if not normalized or any(marker in lower_reason for marker in fallback_markers):
            desc_text = (description or "").lower()
            if any(kw in desc_text for kw in ("agent", "assistant", "copilot", "workflow")):
                area = "AI Agent/æ™ºèƒ½åŠ©æ‰‹æ–¹å‘"
            elif any(kw in desc_text for kw in ("llm", "gpt", "chat", "rag", "prompt")):
                area = "LLM åº”ç”¨æ–¹å‘"
            elif any(kw in desc_text for kw in ("vision", "image", "video", "multimodal")):
                area = "å¤šæ¨¡æ€/è§†è§‰æ–¹å‘"
            else:
                area = "AI åº”ç”¨æˆ–å·¥å…·æ–¹å‘"
            return f"åŸºäºé¡¹ç›®æè¿°ä¸­çš„å…³é”®è¯åˆ¤å®šï¼Œè¯¥é¡¹ç›®ä¸ {area}ç›¸å…³ï¼Œå»ºè®®åç»­ç»“åˆ README åšè¿›ä¸€æ­¥å¤æ ¸ã€‚"

        return normalized

    def _get_category_emoji(self, category: str) -> str:
        """Get emoji for category"""
        emoji_map = {
            'LLM/NLP': 'ğŸ¤–',
            'è®¡ç®—æœºè§†è§‰': 'ğŸ‘',
            'AIå·¥å…·/æ¡†æ¶': 'ğŸ› ',
            'å¤šæ¨¡æ€åº”ç”¨': 'ğŸ¨',
            'å…¶ä»–': 'ğŸ“¦'
        }
        return emoji_map.get(category, 'ğŸ“¦')
